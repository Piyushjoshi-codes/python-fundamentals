{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbfebcc8",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eed634",
   "metadata": {},
   "source": [
    "## What is Pandas ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f698ca0",
   "metadata": {},
   "source": [
    "##### **Pandas is a Python library used for data manipulation, analysis, and cleaning.**\n",
    "##### *The name \"Pandas\" has a reference to both \"Panel Data\", and \"Python Data Analysis\" and was created by Wes McKinney in 2008.*\n",
    "It provides two main data structures:**\n",
    "1. Series (1D data)\n",
    "2. DataFrame (2D tabular data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801bca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking pandas version...\n",
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770cde20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "s = pd.Series([10, 20, 30, 40, 50], index = [\"a\", \"b\", \"c\", \"d\", \"e\"])   #index helps us to create our own labels.\n",
    "s\n",
    "\n",
    "#These labels acts like index through which we can access the data.\n",
    "print(s[\"d\"])    \n",
    "print(s[\"b\" : \"e\"])   #slicing can be done using the modified indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c2630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "    \"star_names\" : [\"Betelguese\", \"Bellatrix\", \"Rigel\", \"Saiph\"],\n",
    "    \"distance_in_light_years\" : [643, 860, 250, 650]\n",
    "}\n",
    "df = pd.DataFrame(data, index = [1, 2, 3, 4])  #index helps us to create our own labels.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbdf409",
   "metadata": {},
   "source": [
    "#### Creating a .csv file for stars and the constellation they belong to with alphabet 'A'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e06d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "star_data_A = pd.read_csv(\"sample.csv\")\n",
    "print(\"0-20 pc → Solar neighborhood\\n20-50 pc → Local stellar region\")\n",
    "print(\"50-100 pc → Nearby galactic disk\\n100+ pc → Distant bright stars\\n\")\n",
    "star_data_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913acc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data_A.head()   #It returns headers and first 5 rows by default if argument not mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data_A.tail()   #It returns headers and last 5 rows by default if argument not mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac13fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data_A.info()   #It states structures, data-types and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f0eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data_A.describe()   #It desribes statistical summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113b7654",
   "metadata": {},
   "source": [
    "#### Column Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff7ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "frame_data = {\n",
    "    \"Planets\" : [\"Mercury\", \"Venus\", \"Earth\", \"Mars\", \"Jupyter\", \"Saturn\", \"Uranus\", \"Neptune\"],\n",
    "    \"Radius_in_km\" : [2439.7, 6051.8, 6371.0, 3389.5, 69911, 58232, 25362, 24622],\n",
    "    \"Distance_from_the_sun_in_AU\" : [0.39, 0.72, 1.00, 1.52, 5.20, 9.54, 19.22, 30.06],\n",
    "    \"Gravitational_acceleration_in_m/s^2\" : [3.7, 8.87, 9.8, 3.7, 24.79, 10.44, 8.69, 11.15]\n",
    "}\n",
    "df = pd.DataFrame(frame_data)\n",
    "print(\"DataFrame Set: \")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af62308",
   "metadata": {},
   "source": [
    "Single Column Selection : It is like indexing where you mention the header and that data inside that header will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e0b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Column Seleciton...\n",
    "df[\"Planets\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6600b2d8",
   "metadata": {},
   "source": [
    "Multiple Column Selction : It helps us mention multiple headers and print the data under that header sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc57459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple Column Selection...\n",
    "df[[\"Planets\", \"Radius_in_km\", \"Distance_from_the_sun_in_AU\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82ee53a",
   "metadata": {},
   "source": [
    "Outputs :\n",
    "1. Output of a single column data is like a type of Series that prints only a single header with no. of data's inside it.\n",
    "2. Output of a multiple data is a DataFrame that prints mentioned headers and no. of data's inside it.\n",
    "Both are different from each other and shows the clear importance between accessibility of a single or a multiple data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c522ef5",
   "metadata": {},
   "source": [
    "#### Row Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad264c1e",
   "metadata": {},
   "source": [
    "Row filtering allows us to access data from specific rows by using conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c4f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "student_data = {\n",
    "    \"name \" : [\"Pia\", \"Hikaru\", \"Judit\", \"Magnus\"],\n",
    "    \"age\" : [29, 23, 24, 19],\n",
    "    \"birth_year\" : [2000, 2002, 2001, 2005],\n",
    "}\n",
    "data_f = pd.DataFrame(student_data)\n",
    "data_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e576cf7",
   "metadata": {},
   "source": [
    "##### Using single conditional statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4e4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_f[\"age\"] > 20)\n",
    "data_f[ data_f[ \"age\"] > 20]    #true terms will be printed out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db248854",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_f[ \"birth_year\"] >= 2002)\n",
    "data_f[ data_f[ \"birth_year\"] >= 2002]    #true terms will be printed out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9a0d8",
   "metadata": {},
   "source": [
    "##### Using multiple conditional statements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d561ad",
   "metadata": {},
   "source": [
    "Here we relate with more than pne conditions to access the specific data. Here the parenthesis are required as unwanted data might get involved resulting error in ouptut.\n",
    "\n",
    "As you can see here '&' is used instead of 'and' operator as '&' is a bitwise-AND operator and...\n",
    "1. '&' operates on bits(integers) while 'and' is used on truth tables(bool values).\n",
    "2. '&' returns an integer value while 'and' returns a last evaluated operand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b8998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for shape of the dataframe...\n",
    "print(f\"Original Shape = {data_f.shape}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d013d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_f[ \"age\"] > 20 & (data_f[ \"birth_year\"] >= 2002))\n",
    "data_1 = data_f[(data_f[ \"age\"] > 20) & (data_f[ \"birth_year\"] >= 2002)]\n",
    "data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f6688",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for shape after filtering...\n",
    "print(f\"Filtered Shape = {data_1.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c89a441",
   "metadata": {},
   "source": [
    "### Sorting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb0168d",
   "metadata": {},
   "source": [
    "#### sort_values() : It sorts the values/data/elements in an ascending order by defaault."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5b80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "earth_composition = {\n",
    "    \"Gases\" : [\"Nitrogen\", \"Oxygen\", \"Carbon Dioxide\", \"Argon\", \"Other Gases\"],\n",
    "    \"percent\" : [78.084, 20.946, 0.042, 0.934, 0.002]\n",
    "}\n",
    "comp_data = pd.DataFrame(earth_composition)\n",
    "comp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting the above compostion value\n",
    "comp_data.sort_values(\"percent\")    #By Default sorts in the ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting in descending order\n",
    "comp_data.sort_values(\"percent\", ascending = False)\n",
    "\n",
    "#when ascending = False, it returns sorting values with descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e486daf",
   "metadata": {},
   "source": [
    "#### Checking the missing values (NaN) inside the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fd83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "presenty_data = {\n",
    "    \"student_name\" : [\"Rahul\", \"Priya\", \"Daksh\", \"Sanya\", \"Durvesh\"], \n",
    "    \"presenty\" : [1, None, 0, 1, None]\n",
    "}\n",
    "p_data = pd.DataFrame(presenty_data)\n",
    "p_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663f483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking how many missing values are there\n",
    "print(p_data.isna())\n",
    "\n",
    "#Checking for the total missing values(NaN) values..\n",
    "print(p_data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d4a1c3",
   "metadata": {},
   "source": [
    "**isna.() returns boolean values. For the missing values such as NaN, None, etc., it returns 'True' otherwise 'False'.**\n",
    "\n",
    "**.sum() here counts the number of the missing values such as NaN, None, etc..., per column.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe10681",
   "metadata": {},
   "source": [
    "### How to handle the missing values ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca17a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as py\n",
    "import numpy as np\n",
    "\n",
    "df2 = pd.read_csv(\"hokage.csv\", na_values = [\" None\", \"None \"])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cb18a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null or missing values\n",
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3009d",
   "metadata": {},
   "source": [
    "**Options to handle missing values :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0fb9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Drop missing rows >>>\n",
    "df2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dd07a9",
   "metadata": {},
   "source": [
    "*As you can see the above output... It usually omits the rows with NaN/ None anywhere in the column. Thus making it less efficient as one requires whole data to handle, store or organize it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93ca0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Fill missing rowa >>>\n",
    "df2_filled = df2.fillna(df2.mean(numeric_only = True))\n",
    "df2_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a827fa27",
   "metadata": {},
   "source": [
    "*As you can see the above output... It usually doesn't change anything in strings or characters and only reacts to the numeric data by which the missing values are filled by using mean of all other values.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc8c761",
   "metadata": {},
   "source": [
    "#### When to drop and when to fill ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b6830f",
   "metadata": {},
   "source": [
    "Use of .dropna() ->\n",
    "1. Use it only when the data is massive and doesn't affect your result.\n",
    "2. Use it only when there are too many NaN values in a single rows.\n",
    "\n",
    "Use of .fillna() ->\n",
    "1. Use it only if the data is much smaller and easily affects the result.\n",
    "2. Use it only when there are fewer NaN values and can be replaced by filling data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef076727",
   "metadata": {},
   "source": [
    "***Real Data-sets almost always contains the missing values.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50430f77",
   "metadata": {},
   "source": [
    "### Learning Groupby and Aggregation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6bf68",
   "metadata": {},
   "source": [
    "#### Using groupb() to an actual data\n",
    "*groupby() helps us group the same strings and return the data without repeating the same row formats.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21624a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df3 = pd.read_csv(\"weather.csv\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb93397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by column\n",
    "df3.groupby(\"City_name\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227ef06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply aggregation functions \n",
    "df3.groupby(\"City_name\").mean(numeric_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f860bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation over mean values\n",
    "#Printing max values over their mean values\n",
    "df3.groupby(\"City_name\").max(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706efacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation over mean values\n",
    "#Printing min values over their mean values\n",
    "df3.groupby(\"City_name\").min(numeric_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db1cd7",
   "metadata": {},
   "source": [
    "#### mean()/max()/min() and numeric_types\n",
    "*mean() calculates the mean values per city, max() calculates maximum values per city and min() calculates minimum values per city.*\n",
    "*'numeric_only = True' allows to work on only numeric types leaving non-numeric data as it is.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4795718",
   "metadata": {},
   "source": [
    "#### Groupby with multiple aggregation functions\n",
    "*groupby with multiple aggregation helps to group and add functions in a single table.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f657509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#groupby with multiple aggregations\n",
    "df3.groupby(\"City_name\").agg({\n",
    "    \" Temperature\": [\"max\", \"min\", \"mean\"],\n",
    "    \" Humidity\": [\"max\", \"min\", \"mean\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e102fe1f",
   "metadata": {},
   "source": [
    "*In above cell, the output prints table as groupby and all the aggregation functions in a single table.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
